{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af8277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.applications import mobilenet_v2\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight \n",
    "from tensorflow.python.keras.preprocessing import image as image_preprocessing\n",
    "\n",
    "import random\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.framework import tensor_util\n",
    "\n",
    "from tensorflow.python.keras.engine import base_layer\n",
    "from tensorflow.python.keras.engine import base_preprocessing_layer\n",
    "from tensorflow.python.keras.preprocessing import image as image_preprocessing\n",
    "from tensorflow.python.keras.utils import control_flow_util\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "#from tensorflow.keras.preprocessing.image import image_dataset_from_directory\n",
    "train_datagen = ImageDataGenerator(validation_split=0.2,\n",
    "                                   rescale=1./255.,\n",
    "                                   shear_range=5,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                  )\n",
    "\n",
    "train_ds = train_datagen.image_dataset_from_directory(\n",
    "    directory='training',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256))\n",
    "validation_ds = train_datagen.image_dataset_from_directory(\n",
    "    directory='validation',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a90f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_shape = (256, 256, 3)\n",
    "\n",
    "base_model=ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape) \n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False    \n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x) \n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dense(50, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x) \n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23fc5a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 383s 3s/step - loss: 4.1001 - accuracy: 0.4030 - val_loss: 1.9816 - val_accuracy: 0.4687\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 391s 3s/step - loss: 0.8616 - accuracy: 0.7460 - val_loss: 1.7853 - val_accuracy: 0.5707\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 1348s 11s/step - loss: 0.4235 - accuracy: 0.8653 - val_loss: 2.1048 - val_accuracy: 0.5414\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 378s 3s/step - loss: 0.1979 - accuracy: 0.9353 - val_loss: 2.0977 - val_accuracy: 0.5758\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 378s 3s/step - loss: 0.1272 - accuracy: 0.9574 - val_loss: 2.2173 - val_accuracy: 0.5889\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 380s 3s/step - loss: 0.0860 - accuracy: 0.9747 - val_loss: 2.3518 - val_accuracy: 0.5848\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 378s 3s/step - loss: 0.0745 - accuracy: 0.9777 - val_loss: 2.5421 - val_accuracy: 0.6111\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 401s 3s/step - loss: 0.0675 - accuracy: 0.9799 - val_loss: 2.7811 - val_accuracy: 0.5697\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 430s 3s/step - loss: 0.1235 - accuracy: 0.9589 - val_loss: 2.9279 - val_accuracy: 0.6071\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 430s 3s/step - loss: 0.1890 - accuracy: 0.9486 - val_loss: 3.4913 - val_accuracy: 0.5505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c97d6c70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99db0978",
   "metadata": {},
   "source": [
    "It seems to be overfitting ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c52747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training/Monet', 'training/VanGogh', 'training/Renoir', 'training/Matisse', 'training/Degas', 'training/Hassam', 'training/Sargent', 'training/Cezanne', 'training/Gauguin', 'training/Pissarro']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory_list = list()\n",
    "for root, dirs, files in os.walk('training', topdown=False):\n",
    "    for name in dirs:\n",
    "        directory_list.append(os.path.join(root, name))\n",
    "\n",
    "print(directory_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a90d8d",
   "metadata": {},
   "source": [
    "New model with batch normalization as a form of regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a045ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(512, kernel_initializer='he_uniform')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "X = Dense(16, kernel_initializer='he_uniform')(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "predictions2 = Dense(10, activation='softmax')(X)\n",
    "\n",
    "model2 = Model(inputs=base_model.input, outputs=predictions2)\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adcd71fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 405s 3s/step - loss: 1.6750 - accuracy: 0.4840 - val_loss: 1.2512 - val_accuracy: 0.6232\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 407s 3s/step - loss: 0.8215 - accuracy: 0.8576 - val_loss: 1.1370 - val_accuracy: 0.6939\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 411s 3s/step - loss: 0.3346 - accuracy: 0.9719 - val_loss: 1.0596 - val_accuracy: 0.7081\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 410s 3s/step - loss: 0.1327 - accuracy: 0.9937 - val_loss: 1.0029 - val_accuracy: 0.7071\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 431s 3s/step - loss: 0.0650 - accuracy: 0.9992 - val_loss: 0.9573 - val_accuracy: 0.7182\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 445s 4s/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.7242\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 434s 3s/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.9374 - val_accuracy: 0.7212\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 417s 3s/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.7323\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 411s 3s/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.7323\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 421s 3s/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.9303 - val_accuracy: 0.7242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca14bc70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0764610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(500, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(20, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.2)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "predictions3 = Dense(10, activation='softmax')(X)\n",
    "\n",
    "model3 = Model(inputs=base_model.input, outputs=predictions3)\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "254938ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 420s 3s/step - loss: 1.7313 - accuracy: 0.4488 - val_loss: 1.1996 - val_accuracy: 0.6384\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 423s 3s/step - loss: 1.0065 - accuracy: 0.7771 - val_loss: 1.1049 - val_accuracy: 0.6798\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 449s 4s/step - loss: 0.5509 - accuracy: 0.9050 - val_loss: 1.0565 - val_accuracy: 0.6970\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 441s 4s/step - loss: 0.3102 - accuracy: 0.9639 - val_loss: 1.0079 - val_accuracy: 0.6949\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 1845s 15s/step - loss: 0.1936 - accuracy: 0.9789 - val_loss: 0.9717 - val_accuracy: 0.7111\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 2557s 21s/step - loss: 0.1220 - accuracy: 0.9935 - val_loss: 0.9397 - val_accuracy: 0.7212\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 608s 5s/step - loss: 0.0932 - accuracy: 0.9942 - val_loss: 0.9181 - val_accuracy: 0.7222\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 434s 3s/step - loss: 0.0639 - accuracy: 0.9970 - val_loss: 0.9134 - val_accuracy: 0.7212\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 728s 6s/step - loss: 0.0502 - accuracy: 0.9982 - val_loss: 0.9603 - val_accuracy: 0.7131\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 424s 3s/step - loss: 0.0419 - accuracy: 0.9987 - val_loss: 0.9661 - val_accuracy: 0.7131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ccde2df0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b42ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(500, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(100, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "predictions4 = Dense(10, activation='softmax')(X)\n",
    "\n",
    "model4 = Model(inputs=base_model.input, outputs=predictions4)\n",
    "model4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9ccd1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 416s 3s/step - loss: 1.4919 - accuracy: 0.5203 - val_loss: 1.0354 - val_accuracy: 0.6697\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 415s 3s/step - loss: 0.6436 - accuracy: 0.8242 - val_loss: 0.9953 - val_accuracy: 0.6859\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 432s 3s/step - loss: 0.2608 - accuracy: 0.9473 - val_loss: 0.9518 - val_accuracy: 0.7152\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 452s 4s/step - loss: 0.1050 - accuracy: 0.9872 - val_loss: 0.9280 - val_accuracy: 0.7051\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 443s 4s/step - loss: 0.0584 - accuracy: 0.9932 - val_loss: 0.9174 - val_accuracy: 0.7152\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 403s 3s/step - loss: 0.0344 - accuracy: 0.9970 - val_loss: 0.8960 - val_accuracy: 0.7283\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 397s 3s/step - loss: 0.0228 - accuracy: 0.9987 - val_loss: 0.9034 - val_accuracy: 0.7232\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 397s 3s/step - loss: 0.0203 - accuracy: 0.9987 - val_loss: 0.9454 - val_accuracy: 0.7101\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 400s 3s/step - loss: 0.0162 - accuracy: 0.9995 - val_loss: 0.9379 - val_accuracy: 0.7273\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 404s 3s/step - loss: 0.0126 - accuracy: 0.9995 - val_loss: 0.9097 - val_accuracy: 0.7333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cd778dc0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a2d36c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 449s 4s/step - loss: 1.4680 - accuracy: 0.5226 - val_loss: 1.0829 - val_accuracy: 0.6556\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 492s 4s/step - loss: 0.6388 - accuracy: 0.8195 - val_loss: 0.9323 - val_accuracy: 0.6990\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 493s 4s/step - loss: 0.2456 - accuracy: 0.9519 - val_loss: 0.9046 - val_accuracy: 0.7101\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 490s 4s/step - loss: 0.1116 - accuracy: 0.9852 - val_loss: 0.8843 - val_accuracy: 0.7192\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 492s 4s/step - loss: 0.0588 - accuracy: 0.9947 - val_loss: 0.8978 - val_accuracy: 0.7131\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 523s 4s/step - loss: 0.0396 - accuracy: 0.9962 - val_loss: 0.9133 - val_accuracy: 0.7192\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 554s 4s/step - loss: 0.0256 - accuracy: 0.9975 - val_loss: 0.9566 - val_accuracy: 0.7040\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 506s 4s/step - loss: 0.0199 - accuracy: 0.9995 - val_loss: 0.9253 - val_accuracy: 0.7040\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 500s 4s/step - loss: 0.0155 - accuracy: 0.9992 - val_loss: 0.9380 - val_accuracy: 0.7141\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 499s 4s/step - loss: 0.0105 - accuracy: 0.9995 - val_loss: 0.9279 - val_accuracy: 0.7242\n"
     ]
    }
   ],
   "source": [
    "history=model4.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9994e0a",
   "metadata": {},
   "source": [
    "try: image augmentation: ImageDataGenerator from keras "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeada31e",
   "metadata": {},
   "source": [
    "make confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21d26eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(100, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(50, kernel_initializer='he_uniform')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "predictions5 = Dense(10, activation='softmax')(X)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "model5 = Model(inputs=base_model.input, outputs=predictions5)\n",
    "model5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1da7845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 420s 3s/step - loss: 1.8236 - accuracy: 0.3902 - val_loss: 1.2502 - val_accuracy: 0.6061\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 446s 4s/step - loss: 1.0924 - accuracy: 0.6843 - val_loss: 1.1040 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 462s 4s/step - loss: 0.6596 - accuracy: 0.8370 - val_loss: 0.9904 - val_accuracy: 0.6869\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 466s 4s/step - loss: 0.3924 - accuracy: 0.9085 - val_loss: 0.9932 - val_accuracy: 0.6798\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 490s 4s/step - loss: 0.2594 - accuracy: 0.9491 - val_loss: 0.9529 - val_accuracy: 0.7121\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 479s 4s/step - loss: 0.1752 - accuracy: 0.9646 - val_loss: 1.0051 - val_accuracy: 0.6939\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 455s 4s/step - loss: 0.1229 - accuracy: 0.9782 - val_loss: 0.9438 - val_accuracy: 0.7111\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 460s 4s/step - loss: 0.0924 - accuracy: 0.9829 - val_loss: 0.9531 - val_accuracy: 0.7071\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 466s 4s/step - loss: 0.0761 - accuracy: 0.9880 - val_loss: 1.0869 - val_accuracy: 0.6960\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 471s 4s/step - loss: 0.0726 - accuracy: 0.9860 - val_loss: 1.0584 - val_accuracy: 0.6980\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 481s 4s/step - loss: 0.0582 - accuracy: 0.9870 - val_loss: 1.0109 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 479s 4s/step - loss: 0.0555 - accuracy: 0.9895 - val_loss: 1.0632 - val_accuracy: 0.7212\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 480s 4s/step - loss: 0.0572 - accuracy: 0.9877 - val_loss: 1.1568 - val_accuracy: 0.7010\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 458s 4s/step - loss: 0.0482 - accuracy: 0.9905 - val_loss: 1.1020 - val_accuracy: 0.7040\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 413s 3s/step - loss: 0.0387 - accuracy: 0.9925 - val_loss: 1.1911 - val_accuracy: 0.6768\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 407s 3s/step - loss: 0.0444 - accuracy: 0.9907 - val_loss: 1.3192 - val_accuracy: 0.6747\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 405s 3s/step - loss: 0.0532 - accuracy: 0.9857 - val_loss: 1.2356 - val_accuracy: 0.6929\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 415s 3s/step - loss: 0.0539 - accuracy: 0.9860 - val_loss: 1.2855 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 444s 4s/step - loss: 0.0478 - accuracy: 0.9887 - val_loss: 1.4180 - val_accuracy: 0.6808\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 457s 4s/step - loss: 0.0523 - accuracy: 0.9857 - val_loss: 1.3111 - val_accuracy: 0.6939\n"
     ]
    }
   ],
   "source": [
    "history_model5=model5.fit(train_ds,epochs=20,validation_data=validation_ds,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd310225",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(100, kernel_initializer='random_normal')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(50, kernel_initializer='random_normal')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "predictions6 = Dense(10, activation='softmax')(X)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "custom_early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=8, \n",
    "    min_delta=0.001, \n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model6 = Model(inputs=base_model.input, outputs=predictions6)\n",
    "model6.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "090887fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "125/125 [==============================] - 1056s 8s/step - loss: 1.7511 - accuracy: 0.4230 - val_loss: 1.2544 - val_accuracy: 0.5939\n",
      "Epoch 2/15\n",
      "125/125 [==============================] - 652s 5s/step - loss: 1.0064 - accuracy: 0.7106 - val_loss: 1.1137 - val_accuracy: 0.6434\n",
      "Epoch 3/15\n",
      "125/125 [==============================] - 710s 6s/step - loss: 0.5755 - accuracy: 0.8543 - val_loss: 0.9331 - val_accuracy: 0.7030\n",
      "Epoch 4/15\n",
      "125/125 [==============================] - 738s 6s/step - loss: 0.3309 - accuracy: 0.9330 - val_loss: 0.9436 - val_accuracy: 0.6990\n",
      "Epoch 5/15\n",
      "125/125 [==============================] - 761s 6s/step - loss: 0.1946 - accuracy: 0.9649 - val_loss: 1.0252 - val_accuracy: 0.6768\n"
     ]
    }
   ],
   "source": [
    "history_model6=model6.fit(train_ds,epochs=15,validation_data=validation_ds,callbacks=[custom_early_stopping,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751fc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b1cb9c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3988 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_input_shape = (256, 256, 3)\n",
    "n_classes = 10\n",
    "images_dir='training'\n",
    "\n",
    "train_datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255.,\n",
    "                                   shear_range=5,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                  )\n",
    "\n",
    "test_set = train_datagen.flow_from_directory('training',target_size=(226,226),batch_size=16,class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a5101e",
   "metadata": {},
   "source": [
    "Testing the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "27551960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  [[0.07220162 0.09561805 0.10533102 0.0970286  0.0554305  0.16482826\n",
      "  0.18173131 0.10521411 0.04832559 0.0742909 ]]\n",
      "preds: [[0.07220162 0.09561805 0.10533102 0.0970286  0.0554305  0.16482826\n",
      "  0.18173131 0.10521411 0.04832559 0.0742909 ]] Pissarro\n",
      "Artist:  Pissarro (probability: 18.17%)\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import cv2\n",
    "labels = test_set.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "img='testfolder/test1.jpg'\n",
    "\n",
    "img = imageio.imread(img)\n",
    "img = cv2.resize(img, dsize=train_input_shape[0:2], )\n",
    "img = image.img_to_array(img)\n",
    "img /= 255.\n",
    "img = np.expand_dims(img, axis=0)\n",
    "p = model6.predict(img)\n",
    "print(\"predictions: \",p)\n",
    "prob = np.amax(p)\n",
    "idx = np.argmax(p)\n",
    "print('preds:',p,labels[idx])\n",
    "\n",
    "print(\"Artist: \", labels[idx].replace('_', ' '), \"(probability: {:.2f}%)\".format(prob*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c683476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 131072)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 100)          13107300    flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 100)          0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100)          400         dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 100)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 50)           5050        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 50)           0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 50)           200         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 50)           0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 10)           510         activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 36,701,172\n",
      "Trainable params: 13,113,160\n",
      "Non-trainable params: 23,588,012\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca362de",
   "metadata": {},
   "source": [
    "Let's turn this into a binary classification problem to see if it improves: (note: after testing the binary model, there is still a bias problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "85cc7da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 798 files belonging to 2 classes.\n",
      "Found 198 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds_bin = image_dataset_from_directory(\n",
    "    directory='training2',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256))\n",
    "validation_ds_bin = image_dataset_from_directory(\n",
    "    directory='validation2',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=16,\n",
    "    image_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "17eec75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(400, activation='relu')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(50, activation='relu')(X)\n",
    "X = Dropout(0.3)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "bin_predictions = Dense(2, activation='sigmoid')(X)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "custom_early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=8, \n",
    "    min_delta=0.001, \n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "bin_model = Model(inputs=base_model.input, outputs=bin_predictions)\n",
    "bin_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec6d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''history_bin_model=bin_model.fit(train_ds_bin,epochs=15,validation_data=validation_ds_bin,\n",
    "                          callbacks=[custom_early_stopping,reduce_lr])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "53989a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = test_data_generator.classes\n",
    "class_labels = list(test_data_generator.class_indices.keys())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "156ad61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cezanne       0.96      0.89      0.93       399\n",
      "       Degas       0.90      0.97      0.93       398\n",
      "     Gauguin       0.97      0.89      0.93       399\n",
      "      Hassam       0.86      0.99      0.92       399\n",
      "     Matisse       0.96      0.92      0.94       399\n",
      "       Monet       0.84      0.95      0.89       399\n",
      "    Pissarro       0.96      0.89      0.92       398\n",
      "      Renoir       0.91      0.96      0.93       399\n",
      "     Sargent       0.99      0.69      0.81       399\n",
      "     VanGogh       0.86      0.97      0.91       399\n",
      "\n",
      "    accuracy                           0.91      3988\n",
      "   macro avg       0.92      0.91      0.91      3988\n",
      "weighted avg       0.92      0.91      0.91      3988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(report)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7659a694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8fcd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
